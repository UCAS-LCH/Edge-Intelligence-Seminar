## 主要方法
模型逐步缩小后，同时训练小模型和大模型。和NAS的差异为，NAS先选好子模型再finetune，本文方法对于每个子模型从不同的维度逐步剪枝和finetune。
## 问题和讨论
1. 网络的训练代价很大
2. 剪枝可以借鉴，尝试不同维度的压缩
3. 剪枝得到的模型和文中的子模型相比效果如何？
